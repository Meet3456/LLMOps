embedding_model:
  provider: "google"
  model_name: "models/text-embedding-004"

retriever:
  top_k: 10
  search_type: "mmr"
  fetch_k: 35
  lambda_mult: 0.5 
  score_threshold: 0.6
 
groq: 
  # two keys: one for compound/tools, one for rag/reasoning/multimodal
  api_keys:
    default_env: "GROQ_API_KEY_DEFAULT"
    compound_env: "GROQ_API_KEY_COMPOUND"

reranker:
  enabled: true
  model_name: "BAAI/bge-reranker-v2-m3"
  top_k_routing: 10      # number of docs used in routing quick check
  top_k_retrieval: 25    # number of docs fetched from FAISS before reranking
  final_k: 5            # final docs sent to RAG LLM
  torch_dtype: "float32"

llm:
  # ROUTER: High speed, specific JSON structure
  router:
    provider: "groq"
    model_name: "llama-3.1-8b-instant"
    temperature: 0.0
    max_tokens: 256

  # RAG LLM  
  rag:
    provider: "groq"
    model_name: "llama-3.3-70b-versatile"
    temperature: 0.1
    max_tokens: 1024
    top_p: 0.9                  
    frequency_penalty: 0.1 
    presence_penalty: 0.1

  # DEEP REASONING LLM
  reasoning:
    provider: "groq"
    model_name: "qwen/qwen3-32b"
    temperature: 0.5
    max_tokens: 4096
    reasoning_format: "parsed"     # parsed | raw | hidden
    reasoning_effort: "default"    # only for Qwen â†’ none | default

  # TOOLING LLM
  tools:
    provider: "groq"
    model_name: "groq/compound-mini"
    temperature: 0
    max_tokens: 1024
    enabled_tools:
      - web_search
      - visit_website
      - browser_automation
      - code_interpreter
      - wolfram_alpha
